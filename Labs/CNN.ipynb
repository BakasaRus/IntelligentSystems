{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 96, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval = 10):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.1%})]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                batch_idx / len(train_loader), loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1%})\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), correct / len(test_loader.dataset)))\n",
    "\n",
    "    return test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "test_batch_size = 500\n",
    "epochs = 15\n",
    "learning_rate = 1.0\n",
    "gamma = 0.7\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "log_interval = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0.0%)]\tLoss: 2.338512\n",
      "Train Epoch: 1 [2500/60000 (4.2%)]\tLoss: 0.777324\n",
      "Train Epoch: 1 [5000/60000 (8.3%)]\tLoss: 0.248125\n",
      "Train Epoch: 1 [7500/60000 (12.5%)]\tLoss: 0.132127\n",
      "Train Epoch: 1 [10000/60000 (16.7%)]\tLoss: 0.209732\n",
      "Train Epoch: 1 [12500/60000 (20.8%)]\tLoss: 0.084632\n",
      "Train Epoch: 1 [15000/60000 (25.0%)]\tLoss: 0.325705\n",
      "Train Epoch: 1 [17500/60000 (29.2%)]\tLoss: 0.253865\n",
      "Train Epoch: 1 [20000/60000 (33.3%)]\tLoss: 0.232634\n",
      "Train Epoch: 1 [22500/60000 (37.5%)]\tLoss: 0.065158\n",
      "Train Epoch: 1 [25000/60000 (41.7%)]\tLoss: 0.111978\n",
      "Train Epoch: 1 [27500/60000 (45.8%)]\tLoss: 0.090508\n",
      "Train Epoch: 1 [30000/60000 (50.0%)]\tLoss: 0.307866\n",
      "Train Epoch: 1 [32500/60000 (54.2%)]\tLoss: 0.053540\n",
      "Train Epoch: 1 [35000/60000 (58.3%)]\tLoss: 0.356208\n",
      "Train Epoch: 1 [37500/60000 (62.5%)]\tLoss: 0.139220\n",
      "Train Epoch: 1 [40000/60000 (66.7%)]\tLoss: 0.099960\n",
      "Train Epoch: 1 [42500/60000 (70.8%)]\tLoss: 0.144574\n",
      "Train Epoch: 1 [45000/60000 (75.0%)]\tLoss: 0.020248\n",
      "Train Epoch: 1 [47500/60000 (79.2%)]\tLoss: 0.107617\n",
      "Train Epoch: 1 [50000/60000 (83.3%)]\tLoss: 0.081868\n",
      "Train Epoch: 1 [52500/60000 (87.5%)]\tLoss: 0.067542\n",
      "Train Epoch: 1 [55000/60000 (91.7%)]\tLoss: 0.116729\n",
      "Train Epoch: 1 [57500/60000 (95.8%)]\tLoss: 0.102257\n",
      "\n",
      "Test set: Average loss: 0.0501, Accuracy: 9833/10000 (98.3%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0.0%)]\tLoss: 0.109457\n",
      "Train Epoch: 2 [2500/60000 (4.2%)]\tLoss: 0.016869\n",
      "Train Epoch: 2 [5000/60000 (8.3%)]\tLoss: 0.036551\n",
      "Train Epoch: 2 [7500/60000 (12.5%)]\tLoss: 0.186115\n",
      "Train Epoch: 2 [10000/60000 (16.7%)]\tLoss: 0.025636\n",
      "Train Epoch: 2 [12500/60000 (20.8%)]\tLoss: 0.174055\n",
      "Train Epoch: 2 [15000/60000 (25.0%)]\tLoss: 0.025848\n",
      "Train Epoch: 2 [17500/60000 (29.2%)]\tLoss: 0.158072\n",
      "Train Epoch: 2 [20000/60000 (33.3%)]\tLoss: 0.094674\n",
      "Train Epoch: 2 [22500/60000 (37.5%)]\tLoss: 0.053313\n",
      "Train Epoch: 2 [25000/60000 (41.7%)]\tLoss: 0.161166\n",
      "Train Epoch: 2 [27500/60000 (45.8%)]\tLoss: 0.202569\n",
      "Train Epoch: 2 [30000/60000 (50.0%)]\tLoss: 0.037915\n",
      "Train Epoch: 2 [32500/60000 (54.2%)]\tLoss: 0.097784\n",
      "Train Epoch: 2 [35000/60000 (58.3%)]\tLoss: 0.098383\n",
      "Train Epoch: 2 [37500/60000 (62.5%)]\tLoss: 0.178871\n",
      "Train Epoch: 2 [40000/60000 (66.7%)]\tLoss: 0.234458\n",
      "Train Epoch: 2 [42500/60000 (70.8%)]\tLoss: 0.072197\n",
      "Train Epoch: 2 [45000/60000 (75.0%)]\tLoss: 0.064186\n",
      "Train Epoch: 2 [47500/60000 (79.2%)]\tLoss: 0.211288\n",
      "Train Epoch: 2 [50000/60000 (83.3%)]\tLoss: 0.290124\n",
      "Train Epoch: 2 [52500/60000 (87.5%)]\tLoss: 0.007055\n",
      "Train Epoch: 2 [55000/60000 (91.7%)]\tLoss: 0.024128\n",
      "Train Epoch: 2 [57500/60000 (95.8%)]\tLoss: 0.045522\n",
      "\n",
      "Test set: Average loss: 0.0356, Accuracy: 9877/10000 (98.8%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0.0%)]\tLoss: 0.018865\n",
      "Train Epoch: 3 [2500/60000 (4.2%)]\tLoss: 0.120787\n",
      "Train Epoch: 3 [5000/60000 (8.3%)]\tLoss: 0.293410\n",
      "Train Epoch: 3 [7500/60000 (12.5%)]\tLoss: 0.026693\n",
      "Train Epoch: 3 [10000/60000 (16.7%)]\tLoss: 0.032303\n",
      "Train Epoch: 3 [12500/60000 (20.8%)]\tLoss: 0.014791\n",
      "Train Epoch: 3 [15000/60000 (25.0%)]\tLoss: 0.018623\n",
      "Train Epoch: 3 [17500/60000 (29.2%)]\tLoss: 0.004750\n",
      "Train Epoch: 3 [20000/60000 (33.3%)]\tLoss: 0.047803\n",
      "Train Epoch: 3 [22500/60000 (37.5%)]\tLoss: 0.045198\n",
      "Train Epoch: 3 [25000/60000 (41.7%)]\tLoss: 0.067598\n",
      "Train Epoch: 3 [27500/60000 (45.8%)]\tLoss: 0.056495\n",
      "Train Epoch: 3 [30000/60000 (50.0%)]\tLoss: 0.028042\n",
      "Train Epoch: 3 [32500/60000 (54.2%)]\tLoss: 0.083433\n",
      "Train Epoch: 3 [35000/60000 (58.3%)]\tLoss: 0.049790\n",
      "Train Epoch: 3 [37500/60000 (62.5%)]\tLoss: 0.444461\n",
      "Train Epoch: 3 [40000/60000 (66.7%)]\tLoss: 0.075123\n",
      "Train Epoch: 3 [42500/60000 (70.8%)]\tLoss: 0.067468\n",
      "Train Epoch: 3 [45000/60000 (75.0%)]\tLoss: 0.108829\n",
      "Train Epoch: 3 [47500/60000 (79.2%)]\tLoss: 0.018308\n",
      "Train Epoch: 3 [50000/60000 (83.3%)]\tLoss: 0.055093\n",
      "Train Epoch: 3 [52500/60000 (87.5%)]\tLoss: 0.100557\n",
      "Train Epoch: 3 [55000/60000 (91.7%)]\tLoss: 0.004259\n",
      "Train Epoch: 3 [57500/60000 (95.8%)]\tLoss: 0.107668\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 9900/10000 (99.0%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0.0%)]\tLoss: 0.028968\n",
      "Train Epoch: 4 [2500/60000 (4.2%)]\tLoss: 0.005268\n",
      "Train Epoch: 4 [5000/60000 (8.3%)]\tLoss: 0.062799\n",
      "Train Epoch: 4 [7500/60000 (12.5%)]\tLoss: 0.013761\n",
      "Train Epoch: 4 [10000/60000 (16.7%)]\tLoss: 0.019068\n",
      "Train Epoch: 4 [12500/60000 (20.8%)]\tLoss: 0.006949\n",
      "Train Epoch: 4 [15000/60000 (25.0%)]\tLoss: 0.050770\n",
      "Train Epoch: 4 [17500/60000 (29.2%)]\tLoss: 0.013083\n",
      "Train Epoch: 4 [20000/60000 (33.3%)]\tLoss: 0.003398\n",
      "Train Epoch: 4 [22500/60000 (37.5%)]\tLoss: 0.077942\n",
      "Train Epoch: 4 [25000/60000 (41.7%)]\tLoss: 0.116821\n",
      "Train Epoch: 4 [27500/60000 (45.8%)]\tLoss: 0.002492\n",
      "Train Epoch: 4 [30000/60000 (50.0%)]\tLoss: 0.019357\n",
      "Train Epoch: 4 [32500/60000 (54.2%)]\tLoss: 0.020477\n",
      "Train Epoch: 4 [35000/60000 (58.3%)]\tLoss: 0.007872\n",
      "Train Epoch: 4 [37500/60000 (62.5%)]\tLoss: 0.196623\n",
      "Train Epoch: 4 [40000/60000 (66.7%)]\tLoss: 0.056790\n",
      "Train Epoch: 4 [42500/60000 (70.8%)]\tLoss: 0.004349\n",
      "Train Epoch: 4 [45000/60000 (75.0%)]\tLoss: 0.007705\n",
      "Train Epoch: 4 [47500/60000 (79.2%)]\tLoss: 0.089632\n",
      "Train Epoch: 4 [50000/60000 (83.3%)]\tLoss: 0.018761\n",
      "Train Epoch: 4 [52500/60000 (87.5%)]\tLoss: 0.045101\n",
      "Train Epoch: 4 [55000/60000 (91.7%)]\tLoss: 0.028471\n",
      "Train Epoch: 4 [57500/60000 (95.8%)]\tLoss: 0.049926\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9894/10000 (98.9%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0.0%)]\tLoss: 0.008697\n",
      "Train Epoch: 5 [2500/60000 (4.2%)]\tLoss: 0.008220\n",
      "Train Epoch: 5 [5000/60000 (8.3%)]\tLoss: 0.054819\n",
      "Train Epoch: 5 [7500/60000 (12.5%)]\tLoss: 0.020104\n",
      "Train Epoch: 5 [10000/60000 (16.7%)]\tLoss: 0.000873\n",
      "Train Epoch: 5 [12500/60000 (20.8%)]\tLoss: 0.015966\n",
      "Train Epoch: 5 [15000/60000 (25.0%)]\tLoss: 0.004370\n",
      "Train Epoch: 5 [17500/60000 (29.2%)]\tLoss: 0.016336\n",
      "Train Epoch: 5 [20000/60000 (33.3%)]\tLoss: 0.004480\n",
      "Train Epoch: 5 [22500/60000 (37.5%)]\tLoss: 0.012909\n",
      "Train Epoch: 5 [25000/60000 (41.7%)]\tLoss: 0.151796\n",
      "Train Epoch: 5 [27500/60000 (45.8%)]\tLoss: 0.025179\n",
      "Train Epoch: 5 [30000/60000 (50.0%)]\tLoss: 0.009114\n",
      "Train Epoch: 5 [32500/60000 (54.2%)]\tLoss: 0.083087\n",
      "Train Epoch: 5 [35000/60000 (58.3%)]\tLoss: 0.064993\n",
      "Train Epoch: 5 [37500/60000 (62.5%)]\tLoss: 0.012787\n",
      "Train Epoch: 5 [40000/60000 (66.7%)]\tLoss: 0.081509\n",
      "Train Epoch: 5 [42500/60000 (70.8%)]\tLoss: 0.032371\n",
      "Train Epoch: 5 [45000/60000 (75.0%)]\tLoss: 0.027155\n",
      "Train Epoch: 5 [47500/60000 (79.2%)]\tLoss: 0.076554\n",
      "Train Epoch: 5 [50000/60000 (83.3%)]\tLoss: 0.008134\n",
      "Train Epoch: 5 [52500/60000 (87.5%)]\tLoss: 0.064085\n",
      "Train Epoch: 5 [55000/60000 (91.7%)]\tLoss: 0.063344\n",
      "Train Epoch: 5 [57500/60000 (95.8%)]\tLoss: 0.002676\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9896/10000 (99.0%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0.0%)]\tLoss: 0.001694\n",
      "Train Epoch: 6 [2500/60000 (4.2%)]\tLoss: 0.012052\n",
      "Train Epoch: 6 [5000/60000 (8.3%)]\tLoss: 0.031962\n",
      "Train Epoch: 6 [7500/60000 (12.5%)]\tLoss: 0.001636\n",
      "Train Epoch: 6 [10000/60000 (16.7%)]\tLoss: 0.126900\n",
      "Train Epoch: 6 [12500/60000 (20.8%)]\tLoss: 0.067275\n",
      "Train Epoch: 6 [15000/60000 (25.0%)]\tLoss: 0.004180\n",
      "Train Epoch: 6 [17500/60000 (29.2%)]\tLoss: 0.009992\n",
      "Train Epoch: 6 [20000/60000 (33.3%)]\tLoss: 0.026754\n",
      "Train Epoch: 6 [22500/60000 (37.5%)]\tLoss: 0.010446\n",
      "Train Epoch: 6 [25000/60000 (41.7%)]\tLoss: 0.005626\n",
      "Train Epoch: 6 [27500/60000 (45.8%)]\tLoss: 0.018238\n",
      "Train Epoch: 6 [30000/60000 (50.0%)]\tLoss: 0.002800\n",
      "Train Epoch: 6 [32500/60000 (54.2%)]\tLoss: 0.033119\n",
      "Train Epoch: 6 [35000/60000 (58.3%)]\tLoss: 0.034806\n",
      "Train Epoch: 6 [37500/60000 (62.5%)]\tLoss: 0.000529\n",
      "Train Epoch: 6 [40000/60000 (66.7%)]\tLoss: 0.007609\n",
      "Train Epoch: 6 [42500/60000 (70.8%)]\tLoss: 0.045864\n",
      "Train Epoch: 6 [45000/60000 (75.0%)]\tLoss: 0.001154\n",
      "Train Epoch: 6 [47500/60000 (79.2%)]\tLoss: 0.088888\n",
      "Train Epoch: 6 [50000/60000 (83.3%)]\tLoss: 0.240013\n",
      "Train Epoch: 6 [52500/60000 (87.5%)]\tLoss: 0.009369\n",
      "Train Epoch: 6 [55000/60000 (91.7%)]\tLoss: 0.004963\n",
      "Train Epoch: 6 [57500/60000 (95.8%)]\tLoss: 0.018110\n",
      "\n",
      "Test set: Average loss: 0.0307, Accuracy: 9900/10000 (99.0%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0.0%)]\tLoss: 0.003452\n",
      "Train Epoch: 7 [2500/60000 (4.2%)]\tLoss: 0.098966\n",
      "Train Epoch: 7 [5000/60000 (8.3%)]\tLoss: 0.076782\n",
      "Train Epoch: 7 [7500/60000 (12.5%)]\tLoss: 0.002725\n",
      "Train Epoch: 7 [10000/60000 (16.7%)]\tLoss: 0.015122\n",
      "Train Epoch: 7 [12500/60000 (20.8%)]\tLoss: 0.012090\n",
      "Train Epoch: 7 [15000/60000 (25.0%)]\tLoss: 0.129980\n",
      "Train Epoch: 7 [17500/60000 (29.2%)]\tLoss: 0.006038\n",
      "Train Epoch: 7 [20000/60000 (33.3%)]\tLoss: 0.005405\n",
      "Train Epoch: 7 [22500/60000 (37.5%)]\tLoss: 0.014729\n",
      "Train Epoch: 7 [25000/60000 (41.7%)]\tLoss: 0.009045\n",
      "Train Epoch: 7 [27500/60000 (45.8%)]\tLoss: 0.012587\n",
      "Train Epoch: 7 [30000/60000 (50.0%)]\tLoss: 0.001462\n",
      "Train Epoch: 7 [32500/60000 (54.2%)]\tLoss: 0.002007\n",
      "Train Epoch: 7 [35000/60000 (58.3%)]\tLoss: 0.009305\n",
      "Train Epoch: 7 [37500/60000 (62.5%)]\tLoss: 0.022182\n",
      "Train Epoch: 7 [40000/60000 (66.7%)]\tLoss: 0.002134\n",
      "Train Epoch: 7 [42500/60000 (70.8%)]\tLoss: 0.011631\n",
      "Train Epoch: 7 [45000/60000 (75.0%)]\tLoss: 0.033963\n",
      "Train Epoch: 7 [47500/60000 (79.2%)]\tLoss: 0.056449\n",
      "Train Epoch: 7 [50000/60000 (83.3%)]\tLoss: 0.005457\n",
      "Train Epoch: 7 [52500/60000 (87.5%)]\tLoss: 0.021714\n",
      "Train Epoch: 7 [55000/60000 (91.7%)]\tLoss: 0.016211\n",
      "Train Epoch: 7 [57500/60000 (95.8%)]\tLoss: 0.001586\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 9902/10000 (99.0%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0.0%)]\tLoss: 0.027339\n",
      "Train Epoch: 8 [2500/60000 (4.2%)]\tLoss: 0.026258\n",
      "Train Epoch: 8 [5000/60000 (8.3%)]\tLoss: 0.178774\n",
      "Train Epoch: 8 [7500/60000 (12.5%)]\tLoss: 0.083399\n",
      "Train Epoch: 8 [10000/60000 (16.7%)]\tLoss: 0.026451\n",
      "Train Epoch: 8 [12500/60000 (20.8%)]\tLoss: 0.004549\n",
      "Train Epoch: 8 [15000/60000 (25.0%)]\tLoss: 0.218039\n",
      "Train Epoch: 8 [17500/60000 (29.2%)]\tLoss: 0.023454\n",
      "Train Epoch: 8 [20000/60000 (33.3%)]\tLoss: 0.035065\n",
      "Train Epoch: 8 [22500/60000 (37.5%)]\tLoss: 0.010747\n",
      "Train Epoch: 8 [25000/60000 (41.7%)]\tLoss: 0.000224\n",
      "Train Epoch: 8 [27500/60000 (45.8%)]\tLoss: 0.021944\n",
      "Train Epoch: 8 [30000/60000 (50.0%)]\tLoss: 0.016814\n",
      "Train Epoch: 8 [32500/60000 (54.2%)]\tLoss: 0.011973\n",
      "Train Epoch: 8 [35000/60000 (58.3%)]\tLoss: 0.032792\n",
      "Train Epoch: 8 [37500/60000 (62.5%)]\tLoss: 0.002509\n",
      "Train Epoch: 8 [40000/60000 (66.7%)]\tLoss: 0.017516\n",
      "Train Epoch: 8 [42500/60000 (70.8%)]\tLoss: 0.100851\n",
      "Train Epoch: 8 [45000/60000 (75.0%)]\tLoss: 0.005965\n",
      "Train Epoch: 8 [47500/60000 (79.2%)]\tLoss: 0.000984\n",
      "Train Epoch: 8 [50000/60000 (83.3%)]\tLoss: 0.025337\n",
      "Train Epoch: 8 [52500/60000 (87.5%)]\tLoss: 0.015953\n",
      "Train Epoch: 8 [55000/60000 (91.7%)]\tLoss: 0.135108\n",
      "Train Epoch: 8 [57500/60000 (95.8%)]\tLoss: 0.051614\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 9909/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0.0%)]\tLoss: 0.046945\n",
      "Train Epoch: 9 [2500/60000 (4.2%)]\tLoss: 0.028719\n",
      "Train Epoch: 9 [5000/60000 (8.3%)]\tLoss: 0.010027\n",
      "Train Epoch: 9 [7500/60000 (12.5%)]\tLoss: 0.072794\n",
      "Train Epoch: 9 [10000/60000 (16.7%)]\tLoss: 0.006094\n",
      "Train Epoch: 9 [12500/60000 (20.8%)]\tLoss: 0.088714\n",
      "Train Epoch: 9 [15000/60000 (25.0%)]\tLoss: 0.003211\n",
      "Train Epoch: 9 [17500/60000 (29.2%)]\tLoss: 0.016082\n",
      "Train Epoch: 9 [20000/60000 (33.3%)]\tLoss: 0.003989\n",
      "Train Epoch: 9 [22500/60000 (37.5%)]\tLoss: 0.011395\n",
      "Train Epoch: 9 [25000/60000 (41.7%)]\tLoss: 0.004995\n",
      "Train Epoch: 9 [27500/60000 (45.8%)]\tLoss: 0.009924\n",
      "Train Epoch: 9 [30000/60000 (50.0%)]\tLoss: 0.000441\n",
      "Train Epoch: 9 [32500/60000 (54.2%)]\tLoss: 0.013446\n",
      "Train Epoch: 9 [35000/60000 (58.3%)]\tLoss: 0.018607\n",
      "Train Epoch: 9 [37500/60000 (62.5%)]\tLoss: 0.004584\n",
      "Train Epoch: 9 [40000/60000 (66.7%)]\tLoss: 0.028699\n",
      "Train Epoch: 9 [42500/60000 (70.8%)]\tLoss: 0.003906\n",
      "Train Epoch: 9 [45000/60000 (75.0%)]\tLoss: 0.001650\n",
      "Train Epoch: 9 [47500/60000 (79.2%)]\tLoss: 0.003907\n",
      "Train Epoch: 9 [50000/60000 (83.3%)]\tLoss: 0.001683\n",
      "Train Epoch: 9 [52500/60000 (87.5%)]\tLoss: 0.022894\n",
      "Train Epoch: 9 [55000/60000 (91.7%)]\tLoss: 0.045034\n",
      "Train Epoch: 9 [57500/60000 (95.8%)]\tLoss: 0.204452\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 9906/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0.0%)]\tLoss: 0.033694\n",
      "Train Epoch: 10 [2500/60000 (4.2%)]\tLoss: 0.032074\n",
      "Train Epoch: 10 [5000/60000 (8.3%)]\tLoss: 0.094891\n",
      "Train Epoch: 10 [7500/60000 (12.5%)]\tLoss: 0.096615\n",
      "Train Epoch: 10 [10000/60000 (16.7%)]\tLoss: 0.004260\n",
      "Train Epoch: 10 [12500/60000 (20.8%)]\tLoss: 0.072315\n",
      "Train Epoch: 10 [15000/60000 (25.0%)]\tLoss: 0.055647\n",
      "Train Epoch: 10 [17500/60000 (29.2%)]\tLoss: 0.035050\n",
      "Train Epoch: 10 [20000/60000 (33.3%)]\tLoss: 0.001033\n",
      "Train Epoch: 10 [22500/60000 (37.5%)]\tLoss: 0.006284\n",
      "Train Epoch: 10 [25000/60000 (41.7%)]\tLoss: 0.018283\n",
      "Train Epoch: 10 [27500/60000 (45.8%)]\tLoss: 0.002688\n",
      "Train Epoch: 10 [30000/60000 (50.0%)]\tLoss: 0.110889\n",
      "Train Epoch: 10 [32500/60000 (54.2%)]\tLoss: 0.005915\n",
      "Train Epoch: 10 [35000/60000 (58.3%)]\tLoss: 0.058100\n",
      "Train Epoch: 10 [37500/60000 (62.5%)]\tLoss: 0.082350\n",
      "Train Epoch: 10 [40000/60000 (66.7%)]\tLoss: 0.021660\n",
      "Train Epoch: 10 [42500/60000 (70.8%)]\tLoss: 0.029976\n",
      "Train Epoch: 10 [45000/60000 (75.0%)]\tLoss: 0.075926\n",
      "Train Epoch: 10 [47500/60000 (79.2%)]\tLoss: 0.052308\n",
      "Train Epoch: 10 [50000/60000 (83.3%)]\tLoss: 0.046700\n",
      "Train Epoch: 10 [52500/60000 (87.5%)]\tLoss: 0.037583\n",
      "Train Epoch: 10 [55000/60000 (91.7%)]\tLoss: 0.002335\n",
      "Train Epoch: 10 [57500/60000 (95.8%)]\tLoss: 0.151532\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 9912/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0.0%)]\tLoss: 0.017082\n",
      "Train Epoch: 11 [2500/60000 (4.2%)]\tLoss: 0.001562\n",
      "Train Epoch: 11 [5000/60000 (8.3%)]\tLoss: 0.001487\n",
      "Train Epoch: 11 [7500/60000 (12.5%)]\tLoss: 0.002116\n",
      "Train Epoch: 11 [10000/60000 (16.7%)]\tLoss: 0.021459\n",
      "Train Epoch: 11 [12500/60000 (20.8%)]\tLoss: 0.001120\n",
      "Train Epoch: 11 [15000/60000 (25.0%)]\tLoss: 0.000485\n",
      "Train Epoch: 11 [17500/60000 (29.2%)]\tLoss: 0.038012\n",
      "Train Epoch: 11 [20000/60000 (33.3%)]\tLoss: 0.002298\n",
      "Train Epoch: 11 [22500/60000 (37.5%)]\tLoss: 0.007732\n",
      "Train Epoch: 11 [25000/60000 (41.7%)]\tLoss: 0.009846\n",
      "Train Epoch: 11 [27500/60000 (45.8%)]\tLoss: 0.001265\n",
      "Train Epoch: 11 [30000/60000 (50.0%)]\tLoss: 0.113376\n",
      "Train Epoch: 11 [32500/60000 (54.2%)]\tLoss: 0.179165\n",
      "Train Epoch: 11 [35000/60000 (58.3%)]\tLoss: 0.016283\n",
      "Train Epoch: 11 [37500/60000 (62.5%)]\tLoss: 0.003193\n",
      "Train Epoch: 11 [40000/60000 (66.7%)]\tLoss: 0.004877\n",
      "Train Epoch: 11 [42500/60000 (70.8%)]\tLoss: 0.012531\n",
      "Train Epoch: 11 [45000/60000 (75.0%)]\tLoss: 0.009883\n",
      "Train Epoch: 11 [47500/60000 (79.2%)]\tLoss: 0.004480\n",
      "Train Epoch: 11 [50000/60000 (83.3%)]\tLoss: 0.005002\n",
      "Train Epoch: 11 [52500/60000 (87.5%)]\tLoss: 0.099805\n",
      "Train Epoch: 11 [55000/60000 (91.7%)]\tLoss: 0.007742\n",
      "Train Epoch: 11 [57500/60000 (95.8%)]\tLoss: 0.077299\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9913/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0.0%)]\tLoss: 0.004239\n",
      "Train Epoch: 12 [2500/60000 (4.2%)]\tLoss: 0.018955\n",
      "Train Epoch: 12 [5000/60000 (8.3%)]\tLoss: 0.022739\n",
      "Train Epoch: 12 [7500/60000 (12.5%)]\tLoss: 0.023631\n",
      "Train Epoch: 12 [10000/60000 (16.7%)]\tLoss: 0.003893\n",
      "Train Epoch: 12 [12500/60000 (20.8%)]\tLoss: 0.027525\n",
      "Train Epoch: 12 [15000/60000 (25.0%)]\tLoss: 0.195221\n",
      "Train Epoch: 12 [17500/60000 (29.2%)]\tLoss: 0.003466\n",
      "Train Epoch: 12 [20000/60000 (33.3%)]\tLoss: 0.002349\n",
      "Train Epoch: 12 [22500/60000 (37.5%)]\tLoss: 0.049378\n",
      "Train Epoch: 12 [25000/60000 (41.7%)]\tLoss: 0.019416\n",
      "Train Epoch: 12 [27500/60000 (45.8%)]\tLoss: 0.007159\n",
      "Train Epoch: 12 [30000/60000 (50.0%)]\tLoss: 0.005603\n",
      "Train Epoch: 12 [32500/60000 (54.2%)]\tLoss: 0.016291\n",
      "Train Epoch: 12 [35000/60000 (58.3%)]\tLoss: 0.014711\n",
      "Train Epoch: 12 [37500/60000 (62.5%)]\tLoss: 0.043233\n",
      "Train Epoch: 12 [40000/60000 (66.7%)]\tLoss: 0.061287\n",
      "Train Epoch: 12 [42500/60000 (70.8%)]\tLoss: 0.002885\n",
      "Train Epoch: 12 [45000/60000 (75.0%)]\tLoss: 0.002603\n",
      "Train Epoch: 12 [47500/60000 (79.2%)]\tLoss: 0.016152\n",
      "Train Epoch: 12 [50000/60000 (83.3%)]\tLoss: 0.030467\n",
      "Train Epoch: 12 [52500/60000 (87.5%)]\tLoss: 0.038473\n",
      "Train Epoch: 12 [55000/60000 (91.7%)]\tLoss: 0.072204\n",
      "Train Epoch: 12 [57500/60000 (95.8%)]\tLoss: 0.004076\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 9911/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0.0%)]\tLoss: 0.001153\n",
      "Train Epoch: 13 [2500/60000 (4.2%)]\tLoss: 0.000677\n",
      "Train Epoch: 13 [5000/60000 (8.3%)]\tLoss: 0.018799\n",
      "Train Epoch: 13 [7500/60000 (12.5%)]\tLoss: 0.066010\n",
      "Train Epoch: 13 [10000/60000 (16.7%)]\tLoss: 0.003011\n",
      "Train Epoch: 13 [12500/60000 (20.8%)]\tLoss: 0.010573\n",
      "Train Epoch: 13 [15000/60000 (25.0%)]\tLoss: 0.003559\n",
      "Train Epoch: 13 [17500/60000 (29.2%)]\tLoss: 0.014098\n",
      "Train Epoch: 13 [20000/60000 (33.3%)]\tLoss: 0.012397\n",
      "Train Epoch: 13 [22500/60000 (37.5%)]\tLoss: 0.007714\n",
      "Train Epoch: 13 [25000/60000 (41.7%)]\tLoss: 0.014462\n",
      "Train Epoch: 13 [27500/60000 (45.8%)]\tLoss: 0.015377\n",
      "Train Epoch: 13 [30000/60000 (50.0%)]\tLoss: 0.025944\n",
      "Train Epoch: 13 [32500/60000 (54.2%)]\tLoss: 0.025395\n",
      "Train Epoch: 13 [35000/60000 (58.3%)]\tLoss: 0.022511\n",
      "Train Epoch: 13 [37500/60000 (62.5%)]\tLoss: 0.011685\n",
      "Train Epoch: 13 [40000/60000 (66.7%)]\tLoss: 0.000611\n",
      "Train Epoch: 13 [42500/60000 (70.8%)]\tLoss: 0.045927\n",
      "Train Epoch: 13 [45000/60000 (75.0%)]\tLoss: 0.020463\n",
      "Train Epoch: 13 [47500/60000 (79.2%)]\tLoss: 0.022820\n",
      "Train Epoch: 13 [50000/60000 (83.3%)]\tLoss: 0.001278\n",
      "Train Epoch: 13 [52500/60000 (87.5%)]\tLoss: 0.003661\n",
      "Train Epoch: 13 [55000/60000 (91.7%)]\tLoss: 0.002589\n",
      "Train Epoch: 13 [57500/60000 (95.8%)]\tLoss: 0.000373\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 9911/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0.0%)]\tLoss: 0.001063\n",
      "Train Epoch: 14 [2500/60000 (4.2%)]\tLoss: 0.009460\n",
      "Train Epoch: 14 [5000/60000 (8.3%)]\tLoss: 0.099385\n",
      "Train Epoch: 14 [7500/60000 (12.5%)]\tLoss: 0.004362\n",
      "Train Epoch: 14 [10000/60000 (16.7%)]\tLoss: 0.005768\n",
      "Train Epoch: 14 [12500/60000 (20.8%)]\tLoss: 0.003320\n",
      "Train Epoch: 14 [15000/60000 (25.0%)]\tLoss: 0.000998\n",
      "Train Epoch: 14 [17500/60000 (29.2%)]\tLoss: 0.134003\n",
      "Train Epoch: 14 [20000/60000 (33.3%)]\tLoss: 0.009569\n",
      "Train Epoch: 14 [22500/60000 (37.5%)]\tLoss: 0.002099\n",
      "Train Epoch: 14 [25000/60000 (41.7%)]\tLoss: 0.002279\n",
      "Train Epoch: 14 [27500/60000 (45.8%)]\tLoss: 0.107269\n",
      "Train Epoch: 14 [30000/60000 (50.0%)]\tLoss: 0.004633\n",
      "Train Epoch: 14 [32500/60000 (54.2%)]\tLoss: 0.009143\n",
      "Train Epoch: 14 [35000/60000 (58.3%)]\tLoss: 0.007763\n",
      "Train Epoch: 14 [37500/60000 (62.5%)]\tLoss: 0.002592\n",
      "Train Epoch: 14 [40000/60000 (66.7%)]\tLoss: 0.205444\n",
      "Train Epoch: 14 [42500/60000 (70.8%)]\tLoss: 0.013960\n",
      "Train Epoch: 14 [45000/60000 (75.0%)]\tLoss: 0.003782\n",
      "Train Epoch: 14 [47500/60000 (79.2%)]\tLoss: 0.008719\n",
      "Train Epoch: 14 [50000/60000 (83.3%)]\tLoss: 0.006678\n",
      "Train Epoch: 14 [52500/60000 (87.5%)]\tLoss: 0.004528\n",
      "Train Epoch: 14 [55000/60000 (91.7%)]\tLoss: 0.010321\n",
      "Train Epoch: 14 [57500/60000 (95.8%)]\tLoss: 0.008126\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 9911/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0.0%)]\tLoss: 0.011829\n",
      "Train Epoch: 15 [2500/60000 (4.2%)]\tLoss: 0.030847\n",
      "Train Epoch: 15 [5000/60000 (8.3%)]\tLoss: 0.002038\n",
      "Train Epoch: 15 [7500/60000 (12.5%)]\tLoss: 0.135552\n",
      "Train Epoch: 15 [10000/60000 (16.7%)]\tLoss: 0.008275\n",
      "Train Epoch: 15 [12500/60000 (20.8%)]\tLoss: 0.001811\n",
      "Train Epoch: 15 [15000/60000 (25.0%)]\tLoss: 0.025764\n",
      "Train Epoch: 15 [17500/60000 (29.2%)]\tLoss: 0.025162\n",
      "Train Epoch: 15 [20000/60000 (33.3%)]\tLoss: 0.024025\n",
      "Train Epoch: 15 [22500/60000 (37.5%)]\tLoss: 0.038595\n",
      "Train Epoch: 15 [25000/60000 (41.7%)]\tLoss: 0.126885\n",
      "Train Epoch: 15 [27500/60000 (45.8%)]\tLoss: 0.003114\n",
      "Train Epoch: 15 [30000/60000 (50.0%)]\tLoss: 0.063319\n",
      "Train Epoch: 15 [32500/60000 (54.2%)]\tLoss: 0.079755\n",
      "Train Epoch: 15 [35000/60000 (58.3%)]\tLoss: 0.001543\n",
      "Train Epoch: 15 [37500/60000 (62.5%)]\tLoss: 0.296600\n",
      "Train Epoch: 15 [40000/60000 (66.7%)]\tLoss: 0.011389\n",
      "Train Epoch: 15 [42500/60000 (70.8%)]\tLoss: 0.002127\n",
      "Train Epoch: 15 [45000/60000 (75.0%)]\tLoss: 0.009311\n",
      "Train Epoch: 15 [47500/60000 (79.2%)]\tLoss: 0.017007\n",
      "Train Epoch: 15 [50000/60000 (83.3%)]\tLoss: 0.000118\n",
      "Train Epoch: 15 [52500/60000 (87.5%)]\tLoss: 0.000252\n",
      "Train Epoch: 15 [55000/60000 (91.7%)]\tLoss: 0.005352\n",
      "Train Epoch: 15 [57500/60000 (95.8%)]\tLoss: 0.079436\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 9911/10000 (99.1%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "    loss = test(model, device, test_loader)\n",
    "    losses.append(loss)\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 648x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(range(1, epochs + 1))\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(range(1, epochs + 1), losses)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}